# ğŸ§  TFG - Aprendizaje Federado

ğŸ“… **ActualizaciÃ³n:** 10/09/2025  
ğŸ”§ **Rama:** `Implementar_version_federada_local`

---

## ğŸ“Š Datasets

El proyecto soporta los datasets **MNIST**, **CIFAR10** y **CIFAR100**.  
La funciÃ³n `get_dataset(dataset: int)` permite seleccionar el dataset y devuelve los objetos necesarios para el entrenamiento y evaluaciÃ³n.

- `0` â†’ MNIST
- `1` â†’ CIFAR10
- `2` â†’ CIFAR100

El preprocesamiento incluye:
- Redimensionado a 224x224 pÃ­xeles.
- ConversiÃ³n a RGB si es necesario.
- NormalizaciÃ³n automÃ¡tica calculada sobre el propio dataset.

---

## ğŸ” Arquitectura del Proyecto

El sistema implementa **aprendizaje federado** usando PyTorch, ResNet18 y el modelo ROLANN.  
Cada cliente tiene su propia instancia de ResNet18 (congelada y en modo evaluaciÃ³n) y una instancia de ROLANN.

- **ResNet18** se usa como extractor de caracterÃ­sticas.
- **ROLANN** realiza la clasificaciÃ³n sobre los vectores extraÃ­dos.

---

## ğŸš€ ImplementaciÃ³n Federada

### DivisiÃ³n del dataset

El dataset se divide entre los clientes usando diferentes estrategias:
- **IID**: DivisiÃ³n equitativa y aleatoria.
- **Dirichlet**: DivisiÃ³n no-IID controlando la heterogeneidad con el parÃ¡metro Î±.
- **Class-less**: Cada cliente tiene acceso solo a un subconjunto de clases.

### Cliente

Cada cliente:
- Entrena localmente su modelo ROLANN usando las caracterÃ­sticas extraÃ­das por su ResNet.
- Publica sus matrices locales (`M`, `U`, `S`) al coordinador mediante MQTT.

### Coordinador

El coordinador:
- Recibe las actualizaciones de todos los clientes.
- Realiza la agregaciÃ³n global usando SVD sobre las matrices recibidas.
- Actualiza el modelo global y publica el resultado para que los clientes lo descarguen.

---

## âš¡ Uso de GPU

El sistema detecta automÃ¡ticamente si hay GPU disponible y mueve los modelos y datos al dispositivo adecuado:

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
```

---

## ğŸ“¡ ComunicaciÃ³n MQTT

La comunicaciÃ³n entre clientes y coordinador se realiza mediante **MQTT** (broker Mosquitto):

- Cada cliente publica en:  
  ```
  federated/client/<client_id>/update
  ```
- El coordinador se suscribe a:  
  ```
  federated/client/+/update
  ```
- El modelo global se publica en:  
  ```
  federated/global_model
  ```

Los datos se serializan con **pickle**, se codifican en **base64** y se envuelven en **JSON** para su transmisiÃ³n.

---

## ğŸ—‚ï¸ Estructura de Carpetas

Ejemplo de estructura de archivos del proyecto:

```
Codigo_tfg/
â”œâ”€â”€ Cliente.py
â”œâ”€â”€ Coordinador.py
â”œâ”€â”€ ROLANN.py
â”œâ”€â”€ fedHEONN.py
â”œâ”€â”€ datasets.py
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â””â”€â”€ data/
```

---

## âœ… Notas

- El proyecto estÃ¡ preparado para experimentar con diferentes particiones de datos y cifrado homomÃ³rfico (TenSEAL).
- La sincronizaciÃ³n entre clientes y coordinador se realiza mediante barreras de threading.
- El cÃ³digo estÃ¡ modularizado para facilitar la extensiÃ³n y pruebas.